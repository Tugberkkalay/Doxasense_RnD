# RUNPOD SERVERLESS ENDPOINT OLUÅTURMA KILAVUZU

## âš ï¸ Ã–NEMLÄ°: Serverless Kullan (GPU Pods deÄŸil!)

**Neden Serverless?**
- âœ… Pay-per-use (sadece kullanÄ±rken Ã¶de)
- âœ… Auto-scaling (Ã§ok upload gelirse otomatik scale)
- âœ… Queue ile mÃ¼kemmel uyum
- âœ… Idle durumda $0 maliyet

**GPU Pods vs Serverless:**
| Ã–zellik | GPU Pods | Serverless (âœ“ Ã–nerilen) |
|---------|----------|-------------------------|
| Maliyet | $0.25/hour (7/24) = $180/ay | $0.25/hour (sadece iÅŸlem sÄ±rasÄ±nda) |
| Idle Cost | $180/ay | $0 |
| Scaling | Manuel | Otomatik |
| Queue | Zor | MÃ¼kemmel |
| 100 dosya/gÃ¼n | $180/ay | ~$5/ay |

---

## ğŸ“‹ ADIM ADIM SERVERLESS ENDPOINT OLUÅTURMA

### 1. Serverless Sekmesine Git
```
Runpod Console â†’ Sol menÃ¼ â†’ "Serverless" (ğŸš€ ikonu)
URL: https://www.runpod.io/console/serverless
```

### 2. "New Endpoint" Butonuna TÄ±kla
SaÄŸ Ã¼stteki "+ New Endpoint" butonu

### 3. Template SeÃ§

**HÄ±zlÄ± BaÅŸlangÄ±Ã§ (Ã–nerilen):**
```
Template: "Transformers" veya "PyTorch 2.1"
(HazÄ±r template, hemen Ã§alÄ±ÅŸÄ±r)
```

**Veya Custom Image (GeliÅŸmiÅŸ):**
```
Docker Image: runpod/pytorch:2.1.0-py3.10-cuda11.8.0-devel
(Kendi handler'Ä±mÄ±zÄ± yÃ¼kleyeceÄŸiz)
```

### 4. GPU SeÃ§
```
GPU Type: RTX A4000 (16GB)
Pricing: Spot ($0.25/hr) veya On-Demand ($0.34/hr)
```

### 5. Configuration

**Container Configuration:**
```
Container Disk: 20 GB
Container Registry Credentials: (boÅŸ bÄ±rak - public image)
Environment Variables:
  (Åimdilik boÅŸ bÄ±rakabilirsin)
```

**Endpoint Configuration:**
```
Name: doxasense-worker
Workers:
  Min: 0 (idle'da 0 worker, maliyet $0)
  Max: 3 (aynÄ± anda max 3 paralel iÅŸlem)
GPUs per Worker: 1
Idle Timeout: 30 seconds
Max Jobs per Worker: 1
Scale Type: Queue Delay (Ã¶nerilen)
```

### 6. Deploy!

"Deploy" butonuna tÄ±kla. 2-3 dakika bekle.

### 7. Endpoint Bilgilerini Al

Deploy sonrasÄ± gÃ¶receksin:
```
Endpoint ID: xxxxxxxxxxxxxxxxxx
Endpoint URL: https://api.runpod.ai/v2/xxxxxxxxxxxxxxxxxx

Ã–rnek:
https://api.runpod.ai/v2/abc123def456
```

### 8. Bana Endpoint URL'ini Ver

Endpoint URL'i kopyala ve bana gÃ¶nder. Ben:
- .env dosyasÄ±na ekleyeceÄŸim
- Backend'i restart edeceÄŸim
- Test edeceÄŸiz!

---

## ğŸ¯ ENDPOINT URL NASIL BULUNUR?

Deploy sonrasÄ±:
1. "Endpoints" listesinde endpoint'ini gÃ¶r
2. Endpoint'e tÄ±kla
3. "Endpoint URL" kopyala (saÄŸ Ã¼stte)

Ã–rnek:
```
https://api.runpod.ai/v2/abc123def456
```

**Bu URL'i bana ver, gerisini ben hallederim! ğŸš€**

---

## ğŸ’¡ ÅÄ°MDÄ°LÄ°K YAPILACAK

1. Runpod Console'a git: https://www.runpod.io/console/serverless
2. "+ New Endpoint" tÄ±kla
3. PyTorch template seÃ§
4. A4000 GPU seÃ§
5. Deploy tÄ±kla
6. Endpoint URL'ini kopyala
7. Bana gÃ¶nder!

Endpoint oluÅŸturduktan sonra URL'i ver, ben hemen entegre edip test ederim! âœ…
